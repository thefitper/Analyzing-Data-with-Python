 partially use some of data for train and testing.
 like 70%/30%
 
 #Function train_test_split()
 randomly splits a dataset into training and testing subsets
 from sklearn.model_selection import train_test_split
 
 x_train,x_test,y_train,y_test = train_test_split(x_data,y_data, test_size=0.3,random_state=0)
 
 use cross validation,
 
 #Functino cross_val_score()
 scores = cross_val_score(lr,x_data,y_data,cv=3)
 
 overfitting , underfitting and model selection.
 -how to pick the best polynomial function.
 
 underfitting = too many noise
 more orderring cause overfitting. (too flexible to data)
 
 ridge regression talks about the coefficient in polynomial regression. alpha represent to the coeffecient ratio response to the equation.

#grid search.
split data to 3 parts, training validation test.

In this lesson, you have learned how to:

Identify over-fitting and under-fitting in a predictive model: Overfitting occurs when a function is too closely fit to the training data points and captures the noise of the data. Underfitting refers to a model that can't model the training data or capture the trend of the data.
Apply Ridge Regression to linear regression models: Ridge regression is a regression that is employed in a Multiple regression model when Multicollinearity occurs.
Tune hyper-parameters of an estimator using Grid search: Grid search is a time-efficient tuning technique that exhaustively computes the optimum values of hyperparameters performed on specific parameter values of estimators.
